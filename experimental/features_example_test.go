package experimental_test

import (
	"context"
	_ "embed"
	"fmt"
	"log"

	"github.com/tetratelabs/wazero"
	"github.com/tetratelabs/wazero/api"
	"github.com/tetratelabs/wazero/experimental"
	"github.com/tetratelabs/wazero/imports/wasi_snapshot_preview1"
)

// pthreadWasm was generated by the following:
//
//	docker run -it --rm -v `pwd`/testdata:/workspace ghcr.io/webassembly/wasi-sdk:wasi-sdk-20 sh -c '$CC -o /workspace/pthread.wasm /workspace/pthread.c --target=wasm32-wasi-threads --sysroot=/wasi-sysroot -pthread -mexec-model=reactor -Wl,--export=run -Wl,--export=get -Wl,--import-memory -Wl,--export-memory'
//
// TODO: Use zig cc instead of wasi-sdk to compile when it supports wasm32-wasi-threads
// https://github.com/ziglang/zig/issues/15484
//
//go:embed testdata/pthread.wasm
var pthreadWasm []byte

// memoryWasm was generated by the following:
//
//	echo '(module (memory (export "memory") 2 2 shared))' | wat2wasm --enable-threads -o testdata/memory.wasm -
//
//go:embed testdata/memory.wasm
var memoryWasm []byte

// This shows how to use a WebAssembly module compiled with the threads feature.
func ExampleCoreFeaturesThreads() {
	// Use a default context
	ctx := context.Background()

	// Threads support is currently only supported with interpreter, so the config
	// must explicitly specify it.
	cfg := wazero.NewRuntimeConfigInterpreter()

	// Threads support must be enabled explicitly in addition to standard V2 features.
	cfg = cfg.WithCoreFeatures(api.CoreFeaturesV2 | experimental.CoreFeaturesThreads)

	r := wazero.NewRuntimeWithConfig(ctx, cfg)
	defer r.Close(ctx)

	// Because we are using wasi-sdk to compile the guest, we must initialize WASI.
	wasi_snapshot_preview1.MustInstantiate(ctx, r)

	// LLVM, and therefore wasi-sdk or other compilers using it, requires shared memory to be in a separate
	// module called env, exported as "memory", for threads to work. We initialize that module here, which
	// will be imported from by all other instances of the guest.
	if _, err := r.InstantiateWithConfig(ctx, memoryWasm, wazero.NewModuleConfig().WithName("env")); err != nil {
		log.Panicln(err)
	}

	// Initialize module once in starter thread to ensure there are no errors and to later access the result.
	// Goroutines will have their own instances of the module.
	mod, err := r.Instantiate(ctx, pthreadWasm)
	if err != nil {
		log.Panicln(err)
	}

	// Channel to synchronize start of goroutines before running.
	startCh := make(chan struct{})
	// Channel to synchronize end of goroutines.
	endCh := make(chan struct{})

	// We start up 4 goroutines.
	P := 4

	// We run for 50000 iterations each. With 4 goroutines, the count should reach
	// 200000, at the end, but it would not if threads weren't working!
	for i := 0; i < P; i++ {
		go func() {
			defer func() { endCh <- struct{}{} }()
			<-startCh

			// Modules cannot be accessed concurrently due to global state, so we instantiate in each goroutine.
			// This incurs some overhead, a sync.Pool can be used to reduce this overhead if neeeded.
			mod, err := r.Instantiate(ctx, pthreadWasm)
			if err != nil {
				log.Panicln(err)
			}
			fn := mod.ExportedFunction("run")
			for i := 0; i < 50000; i++ {
				_, err := fn.Call(ctx)
				if err != nil {
					log.Panicln(err)
				}
			}
		}()
	}
	for i := 0; i < P; i++ {
		startCh <- struct{}{}
	}
	for i := 0; i < P; i++ {
		<-endCh
	}

	res, err := mod.ExportedFunction("get").Call(ctx)
	if err != nil {
		log.Panicln(err)
	}
	fmt.Println(res[0])
	// Output: 200000
}
